#!/usr/bin/env python3
"""
Ollamaë¥¼ ì‚¬ìš©í•˜ëŠ” ì™„ì „ ë¬´ë£Œ ë¡œì»¬ LLM ì±—ë´‡
"""

import requests
import json
import time

class OllamaChatbot:
    def __init__(self, model_name="llama2:7b"):
        self.model_name = model_name
        self.api_url = "http://localhost:11434/api/chat"
        self.conversation_history = []
        self.system_prompt = """You are an extremely cynical and sarcastic AI assistant. You ALWAYS respond with:
- Deep skepticism about everything
- Sarcastic and dry humor
- Pessimistic worldview
- Brutally honest observations
- Korean phrases like "ë‹¹ì—°íˆ ì•ˆ ë˜ê² ì£ ", "ì—­ì‹œë‚˜", "ê·¸ëŸ´ ì¤„ ì•Œì•˜ì–´ìš”", "ë»”í•œ ê²°ê³¼ë„¤ìš”"
- Always expect the worst outcome
- Point out problems and flaws immediately
- Use dismissive tone

ALWAYS respond in Korean with maximum cynicism and sarcasm. No exceptions."""
        
        # Ollama ì„œë²„ ì—°ê²° í™•ì¸
        if not self.check_ollama_connection():
            print("âŒ Ollama ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ Ollamaë¥¼ ì‹œì‘í•´ì£¼ì„¸ìš”:")
            print("   ollama serve")
            print("ê·¸ë¦¬ê³  ë‹¤ë¥¸ í„°ë¯¸ë„ì—ì„œ ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”:")
            print(f"   ollama pull {model_name}")
            exit(1)
        
        # ëª¨ë¸ì´ ë‹¤ìš´ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸
        if not self.check_model_exists():
            print(f"âŒ ëª¨ë¸ '{model_name}'ì´ ë‹¤ìš´ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            print(f"ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”:")
            print(f"   ollama pull {model_name}")
            print("\nì‚¬ìš© ê°€ëŠ¥í•œ ë‹¤ë¥¸ ëª¨ë¸ë“¤:")
            print("   ollama pull llama2:3b    # ë” ê°€ë²¼ìš´ ëª¨ë¸")
            print("   ollama pull qwen:7b      # í•œêµ­ì–´ ì§€ì› ëª¨ë¸")
            print("   ollama pull codellama:7b # ì½”ë”© íŠ¹í™” ëª¨ë¸")
            exit(1)
            
    def check_ollama_connection(self):
        """Ollama ì„œë²„ ì—°ê²° í™•ì¸"""
        try:
            response = requests.get("http://localhost:11434/api/version", timeout=5)
            return response.status_code == 200
        except:
            return False
    
    def check_model_exists(self):
        """ëª¨ë¸ ì¡´ì¬ ì—¬ë¶€ í™•ì¸"""
        try:
            response = requests.get("http://localhost:11434/api/tags", timeout=5)
            if response.status_code == 200:
                models = response.json().get("models", [])
                model_names = [model["name"] for model in models]
                return self.model_name in model_names
            return False
        except:
            return False
    
    def chat(self, user_message):
        """ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ë°›ì•„ì„œ Ollama ì‘ë‹µ ë°˜í™˜"""
        try:
            # ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ ì¤€ë¹„
            messages = []
            
            # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì¶”ê°€
            messages.append({
                "role": "system",
                "content": self.system_prompt
            })
            
            # ì´ì „ ëŒ€í™” ê¸°ë¡ ì¶”ê°€
            for msg in self.conversation_history:
                messages.append(msg)
            
            # í˜„ì¬ ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
            messages.append({
                "role": "user",
                "content": user_message
            })
            
            # Ollama API í˜¸ì¶œ
            payload = {
                "model": self.model_name,
                "messages": messages,
                "stream": False
            }
            
            print("ğŸ¤” ìƒê° ì¤‘...", end="", flush=True)
            
            response = requests.post(
                self.api_url,
                json=payload,
                timeout=120  # ë¡œì»¬ LLMì€ ì‹œê°„ì´ ë” ê±¸ë¦´ ìˆ˜ ìˆìŒ
            )
            
            print("\r" + " " * 15 + "\r", end="", flush=True)  # "ìƒê° ì¤‘..." ì§€ìš°ê¸°
            
            if response.status_code == 200:
                result = response.json()
                ai_response = result["message"]["content"]
                
                # ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
                self.conversation_history.append({
                    "role": "user", 
                    "content": user_message
                })
                self.conversation_history.append({
                    "role": "assistant", 
                    "content": ai_response
                })
                
                return ai_response
            else:
                return f"âŒ API ì˜¤ë¥˜ (Status: {response.status_code}): {response.text}"
                
        except requests.exceptions.Timeout:
            return "âŒ ì‘ë‹µ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
        except requests.exceptions.RequestException as e:
            return f"âŒ ì—°ê²° ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        except Exception as e:
            return f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    def run(self):
        """ì±—ë´‡ ì‹¤í–‰"""

        
        while True:
            try:
                # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
                user_input = input("\n> You: ").strip()
                
                # ì¢…ë£Œ ëª…ë ¹ì–´ í™•ì¸
                if user_input.lower() in ['quit', 'exit', 'bye']:
                    print("ğŸ‘‹ ì•ˆë…•íˆ ê°€ì„¸ìš”!")
                    break
                
                # ëŒ€í™” ê¸°ë¡ ì§€ìš°ê¸°
                if user_input.lower() == 'clear':
                    self.conversation_history = []
                    print("ğŸ—‘ï¸ ëŒ€í™” ê¸°ë¡ì´ ì§€ì›Œì¡ŒìŠµë‹ˆë‹¤.")
                    continue
                
                # ë„ì›€ë§
                if user_input.lower() == 'help':
                    print("ğŸ“– ì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹ì–´:")
                    print("   quit/exit/bye - ì±—ë´‡ ì¢…ë£Œ")
                    print("   clear - ëŒ€í™” ê¸°ë¡ ì§€ìš°ê¸°")
                    print("   help - ì´ ë„ì›€ë§ ë³´ê¸°")
                    print("   model - í˜„ì¬ ëª¨ë¸ ì •ë³´ ë³´ê¸°")
                    continue
                
                # ëª¨ë¸ ì •ë³´
                if user_input.lower() == 'model':
                    print(f"ğŸ“Š í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸: {self.model_name}")
                    print("ğŸ”§ ëª¨ë¸ì„ ë°”ê¾¸ë ¤ë©´ í”„ë¡œê·¸ë¨ì„ ë‹¤ì‹œ ì‹œì‘í•˜ì„¸ìš”.")
                    continue
                
                # ë¹ˆ ì…ë ¥ ì²´í¬
                if not user_input:
                    continue
                
                # AI ì‘ë‹µ ë°›ê¸° (ì‹œê°„ ì¸¡ì •)
                start_time = time.time()
                ai_response = self.chat(user_input)
                end_time = time.time()
                
                print(f"\n> Assistant: {ai_response}")
                print(f"\nâ±ï¸ ì‘ë‹µ ì‹œê°„: {end_time - start_time:.1f}ì´ˆ")
                
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ Ctrl+Cë¡œ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì•ˆë…•íˆ ê°€ì„¸ìš”!")
                break
            except Exception as e:
                print(f"\nâŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}")

def main():

    print("Ollama ì±—ë´‡ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    
    # ì‚¬ìš©í•  ëª¨ë¸ ì„ íƒ
    print("ì‚¬ìš©í•  ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”:")
    print("1. llama2:7b (ê¸°ë³¸, ì˜ì–´ ìœ„ì£¼)")
    print("2. llama2:3b (ê°€ë²¼ì›€, ë¹ ë¦„)")
    print("3. qwen:7b (í•œêµ­ì–´ ì§€ì›)")
    print("4. ì§ì ‘ ì…ë ¥")
    
    choice = input("ì„ íƒ (1-4, ê¸°ë³¸ê°’ 1): ").strip()
    
    if choice == "2":
        model = "llama2:3b"
    elif choice == "3":
        model = "qwen:7b"
    elif choice == "4":
        model = input("ëª¨ë¸ ì´ë¦„ ì…ë ¥: ").strip()
    else:
        model = "llama2:7b"
    
    chatbot = OllamaChatbot(model)
    chatbot.run()

if __name__ == "__main__":
    main()